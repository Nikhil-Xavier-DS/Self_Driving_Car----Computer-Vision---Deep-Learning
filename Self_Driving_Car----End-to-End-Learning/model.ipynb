{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Udacity P3: Behavior Cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from library import *\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "tf.python.control_flow_ops = tf\n",
    "dropout_rate = 0.25\n",
    "learning_rate = 1e-03\n",
    "\n",
    "# Number of neurons\n",
    "neuron_100 = 100\n",
    "neuron_50 = 50\n",
    "neuron_10 = 10\n",
    "neuron_1 = 1\n",
    "\n",
    "# Number of frames in each convolution layers\n",
    "conv_layer_1 = 24\n",
    "conv_layer_2 = 36\n",
    "conv_layer_3 = 48\n",
    "conv_layer_4 = 64\n",
    "\n",
    "# Number of epochs\n",
    "epoch_no = 5\n",
    "pooling_size = (2,2) \n",
    "activation_func = 'relu'\n",
    "loss_type = 'mean_squared_error'\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  generator function to augment and tune train data\n",
    "from train_generator_lib import train_generator\n",
    "#  generator function to tune validation data\n",
    "from valid_generator_lib import valid_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6445 4557 1138 750\n",
      "Epoch 1/5\n",
      "19987/20000 [============================>.] - ETA: 3s - loss: 0.0210 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NIKHIL XAVIER\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\engine\\training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: saving model to C:/Users/NIKHIL XAVIER/git/Self-Driving-Car/P3/CarND-Behavioral-Cloning-P3-master/checkpoint2/check-00-0.0118.hdf5\n",
      "20043/20000 [==============================] - 5097s - loss: 0.0210 - val_loss: 0.0118\n",
      "Epoch 2/5\n",
      "19971/20000 [============================>.] - ETA: 8s - loss: 0.0142 Epoch 00001: saving model to C:/Users/NIKHIL XAVIER/git/Self-Driving-Car/P3/CarND-Behavioral-Cloning-P3-master/checkpoint2/check-01-0.0110.hdf5\n",
      "20029/20000 [==============================] - 6355s - loss: 0.0141 - val_loss: 0.0110\n",
      "Epoch 3/5\n",
      "19986/20000 [============================>.] - ETA: 3s - loss: 0.0129 Epoch 00002: saving model to C:/Users/NIKHIL XAVIER/git/Self-Driving-Car/P3/CarND-Behavioral-Cloning-P3-master/checkpoint2/check-02-0.0126.hdf5\n",
      "20044/20000 [==============================] - 4610s - loss: 0.0129 - val_loss: 0.0126\n",
      "Epoch 4/5\n",
      "19996/20000 [============================>.] - ETA: 1s - loss: 0.0124 Epoch 00003: saving model to C:/Users/NIKHIL XAVIER/git/Self-Driving-Car/P3/CarND-Behavioral-Cloning-P3-master/checkpoint2/check-03-0.0116.hdf5\n",
      "20051/20000 [==============================] - 6308s - loss: 0.0124 - val_loss: 0.0116\n",
      "Epoch 5/5\n",
      "19965/20000 [============================>.] - ETA: 9s - loss: 0.0116 Epoch 00004: saving model to C:/Users/NIKHIL XAVIER/git/Self-Driving-Car/P3/CarND-Behavioral-Cloning-P3-master/checkpoint2/check-04-0.0101.hdf5\n",
      "20024/20000 [==============================] - 5492s - loss: 0.0116 - val_loss: 0.0101\n",
      "Saved model to disk\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 160, 320, 3)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 156, 316, 24)  1824        lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 78, 158, 24)   0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 74, 154, 36)   21636       maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 37, 77, 36)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 33, 73, 48)    43248       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 16, 36, 48)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 14, 34, 64)    27712       maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 7, 17, 64)     0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 7616)          0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           761700      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 100)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 50)            5050        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 50)            0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            510         dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             11          dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 861,691\n",
      "Trainable params: 861,691\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from keras.models import model_from_json\n",
    "# images of size are 320x160\n",
    "local_data_path = \"C:/Users/NIKHIL XAVIER/git/Self-Driving-Car/P3/CarND-Behavioral-Cloning-P3-master/data\"\n",
    "os.chdir(r\"C:/Users/NIKHIL XAVIER/git/Self-Driving-Car/P3/CarND-Behavioral-Cloning-P3-master/data\")\n",
    "#os.chdir(r\"C:\\Users\\NIKHIL XAVIER\\git\\Self-Driving-Car\\P3\\CarND-Behavioral-Cloning-P3-master\\data\")\n",
    "\n",
    "new_data_path = os.path.join(local_data_path, \"IMG/\", \"*.jpg\")\n",
    "final_list = []\n",
    "turn_str =[]\n",
    "turn_lft = []\n",
    "turn_rgt = []\n",
    "\n",
    "df = pd.io.parsers.read_csv(os.path.join(local_data_path, 'driving_log.csv'))\n",
    "# Use as dataframe\n",
    "df = pd.read_csv('driving_log.csv', header=0)\n",
    "df.columns = [\"center\", \"left\",\"right\", \"steering\", \"throttle\", \"break\", \"speed\"]\n",
    "df.drop(['throttle', 'break', 'speed'], axis = 1, inplace = True)\n",
    "    \n",
    "for counter in range(len(df)):\n",
    "    keep_prob = random.random()\n",
    "        if (df[\"steering\"][counter] >0.20 and df[\"steering\"][counter] <=0.50):\n",
    "            new_steering = df[\"steering\"][counter]*(1.0 + np.random.uniform(-1,1)/100.0)\n",
    "            turn_rgt.append([df[\"center\"][counter], df[\"left\"][counter], df[\"right\"][counter], new_steering])\n",
    "            new_steering = df[\"steering\"][counter]*(1.0 + np.random.uniform(-1,1)/100.0)\n",
    "            turn_rgt.append([df[\"center\"][counter], df[\"left\"][counter], df[\"right\"][counter], new_steering])\n",
    "\n",
    "        elif (df[\"steering\"][counter] >= -0.50 and df[\"steering\"][counter] < -0.15):\n",
    "            new_steering = df[\"steering\"][counter]*(1.0 + np.random.uniform(-1,1)/100.0)\n",
    "            turn_lft.append([df[\"center\"][counter], df[\"left\"][counter], df[\"right\"][counter], new_steering])\n",
    "            new_steering = df[\"steering\"][counter]*(1.0 + np.random.uniform(-1,1)/100.0)\n",
    "            turn_lft.append([df[\"center\"][counter], df[\"left\"][counter], df[\"right\"][counter], new_steering])\n",
    "\n",
    "        elif (df[\"steering\"][counter] > -0.02 and df[\"steering\"][counter] < 0.02):\n",
    "            if (keep_prob <=0.90):\n",
    "                turn_str.append([df[\"center\"][counter], df[\"left\"][counter], df[\"right\"][counter], df[\"steering\"][counter]])\n",
    "            elif (keep_prob >0.90):\n",
    "                turn_str.append([df[\"center\"][counter], df[\"left\"][counter], df[\"right\"][counter], df[\"steering\"][counter]])\n",
    "\n",
    "                \n",
    "    final_list = turn_rgt + turn_lft + turn_str\n",
    "    print(len(final_list), len(turn_str), len(turn_lft), len(turn_rgt))\n",
    "    random.shuffle(final_list)\n",
    "                \n",
    "# create sets for validation data set and train data set\n",
    "df_train, df_valid = sklearn.model_selection.train_test_split(final_list, test_size=.20)\n",
    "\n",
    "# Model architecture\n",
    "model = models.Sequential()\n",
    "model.add(layers.core.Lambda(lambda x: (x / 127.5 - 1.), input_shape = (160,320,3)))\n",
    "model.add(layers.convolutional.Convolution2D(conv_layer_1, 5, 5, activation=activation_func))\n",
    "model.add(layers.pooling.MaxPooling2D(pool_size=pooling_size))\n",
    "model.add(layers.convolutional.Convolution2D(conv_layer_2, 5, 5, activation=activation_func))\n",
    "model.add(layers.pooling.MaxPooling2D(pool_size=pooling_size))\n",
    "model.add(layers.convolutional.Convolution2D(conv_layer_3, 5, 5, activation=activation_func))\n",
    "model.add(layers.pooling.MaxPooling2D(pool_size=pooling_size))\n",
    "model.add(layers.convolutional.Convolution2D(conv_layer_4, 3, 3, activation=activation_func))\n",
    "model.add(layers.pooling.MaxPooling2D(pool_size=pooling_size))\n",
    "model.add(layers.core.Flatten())\n",
    "model.add(layers.core.Dense(neuron_100, activation=activation_func))\n",
    "model.add(layers.core.Dropout(dropout_rate))\n",
    "model.add(layers.core.Dense(neuron_50, activation=activation_func))\n",
    "model.add(layers.core.Dropout(dropout_rate))\n",
    "model.add(layers.core.Dense(neuron_10, activation=activation_func))\n",
    "model.add(layers.core.Dense(neuron_1))\n",
    "model.compile(optimizer=optimizers.Adam(lr=learning_rate), loss=loss_type)\n",
    "    \n",
    "nb_epoch = 5\n",
    "samples_per_epoch = 20000\n",
    "nb_val_samples = 2000\n",
    "  \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "path_link=\"C:/Users/NIKHIL XAVIER/git/Self-Driving-Car/P3/CarND-Behavioral-Cloning-P3-master/checkpoint2/check-{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath= path_link, verbose=1, save_best_only=False)\n",
    "callbacks_list = [checkpoint]\n",
    "    \n",
    "train_generator = train_generator(df_train, batch_size=batch_size, key = 1)\n",
    "validation_generator = valid_generator(df_valid, batch_size=batch_size, key = 0)\n",
    "\n",
    "history_object = model.fit_generator(train_generator, samples_per_epoch= samples_per_epoch,\n",
    "                                     validation_data=validation_generator,\n",
    "                                     nb_val_samples=nb_val_samples, nb_epoch=nb_epoch, verbose=1, callbacks=callbacks_list)\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"C:/Users/NIKHIL XAVIER/git/Self-Driving-Car/P3/CarND-Behavioral-Cloning-P3-master/model_final.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save(\"C:/Users/NIKHIL XAVIER/git/Self-Driving-Car/P3/CarND-Behavioral-Cloning-P3-master/model_final.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
